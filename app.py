# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gNVvHqkfk8fJ7o5NGZCvHVJN4fW4foWT
"""

#Web Interface with Streamlit
import streamlit as st

# Streamlit app
st.title("Toxic Comment Classification")

# User input
user_input = st.text_area("Enter comment:")

# Model prediction
if user_input:
    # Tokenize the input text
    inputs = tokenizer(user_input, return_tensors='pt', padding=True, truncation=True)

    # Prediction
    with torch.no_grad():
        output = odd_model(**inputs)
        prediction = torch.argmax(output, dim=-1).item()

    # Display result
    if prediction == 1:
        st.markdown("**Toxic**")
    else:
        st.markdown("**Non-Toxic**")

    # Display emoji reaction and confidence score
    st.markdown("Confidence Score: {:.2f}".format(torch.max(output.softmax(dim=-1)).item()))